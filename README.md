# Teaching AI to recognize chord progressions based on their geometric representation on a guitar fretboard

For my project, I wanted to utilize the transformer model to classify the key of a given chord progression. From what I found online, most music analysis algorithms utilize frequency content to classify or generate music. This makes sense---I suppose in the simplest terms music can be compactly described as interesting combinations of frequencies that sound pleasing to the human ear. After all, music elements such as pitch, tone, harmony, timbre, melody, rhythm, and tempo are all described by frequency relations. However, this seems very unintuitive to me at a very fundamental level. When people learn how to play the guitar, or any intrument for that matter, they almost never bother to learn the frequencies of notes. Learning music is often geometric; we say that 'this' finger pattern sounds especially good next to 'that' finger pattern. For guitar specifically, we learn songs by reading guitar tablature. An example of guitar tab is shown 
